<!DOCTYPE html>
<!-- saved from url=(0047)https://omar.website/posts/against-recognition/ -->
<html lang="en-us"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Against recognition</title>
    
    

     <meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@rsnous">
<meta name="twitter:creator" content="@rsnous">
<meta name="twitter:title" content="Against recognition">
<meta name="twitter:description" content="Post-it notes made of sound; the reMarkable tablet&#39;s UI; a Dynamicland scrapbook">
<meta name="twitter:image" content="https://omar.website/posts/against-recognition/departures.jpg">
 

    <link rel="icon" type="image/png" href="https://omar.website/favicon-96x96.png">

    <link rel="stylesheet" href="./assets/recognition/style.css">
    

    <link href="https://omar.website/posts/index.xml" rel="alternate" type="application/rss+xml" title="Omar Rizwan">

    <meta name="generator" content="Hugo 0.89.4">
  </head>
  <body>
    <header>
      <a href="https://omar.website/">
        Omar Rizwan
      </a>
    </header>
    <article>

<main>
  <article>
    <h1>Against recognition</h1>
    
    <time>June 28, 2021</time>
    
    <div>
      <!-- I'm setting this page in [whatever it ends up set in] so I feel
more comfortable jotting random notes and stuff down. -->
<script src="./assets/recognition/hugo-sidenotes.js.download"></script>
<link rel="stylesheet" href="./assets/recognition/hugo-sidenotes.css">
<style>
body { background: #fff0df; }
article { font-family: monospace; font-size: 105%; line-height: 160%; }
article h1 { font-family: Helvetica, sans-serif; font-size: 110%; } 
.figure img { max-height: 1000px; max-width: 100%; }
</style>
<p>(This post was originally part of an email update to <a href="http://github.com/sponsors/osnr">my GitHub
sponsors</a>. I'm making it public
because I like it. It's a little less formal than most things on my
site.)</p>
<hr>
<div class="figure">
<img src="./assets/recognition/thermal.png" alt="tweet from Robin Sloan about how thermal
printers are magical">
</div>
<p>at Dynamicland, I had this idea for an 'audio recorder' or 'audio
note' device -- it would be a thing that has a push button, a
microphone, and a receipt printer:</p>
<ol>
<li>you hold the button down to record<input type="checkbox" class="footnote-toggle" id="footnote-toggle-fn:1"><a class="footnote-ref note-ref" role="doc-noteref"><sup id="fnref:1"><label class="footnote-label" for="footnote-toggle-fn:1">1</label></sup></a><div class="side">
<p><span class="bg-number">1</span> that is, it's push-to-talk /
<a href="https://twitter.com/search?q=from%3Arsnous%20spring%2Dloaded">spring-loaded</a>&nbsp;</p>
</div></li>
<li>say something / make whatever sound you want</li>
<li>let go of the button</li>
<li>the device immediately (or even in real time, while you're
speaking?) prints out a little receipt that 'contains' (that
<a href="https://twitter.com/rsnous/status/1403032642858201092"><em>is</em></a>) the
audio that it just recorded<input type="checkbox" class="footnote-toggle" id="footnote-toggle-fn:2"><a class="footnote-ref note-ref" role="doc-noteref"><sup id="fnref:2"><label class="footnote-label" for="footnote-toggle-fn:2">2</label></sup></a><div class="side">
<p><span class="bg-number">2</span> It's strange -- the detail that the printer is a <em>receipt
printer</em> feels very important. that <em>the printout comes out right
at hand</em>, like a Polaroid (rather than out of a printer somewhere
else in the room), and that the printout is <em>fast</em> (not a laser
printer churning for 30 seconds before spitting out a page). it
helps create this sense of lightness and 'post-it-ness'&nbsp;</p>
</div></li>
<li>then you can put that sound (receipt) down<input type="checkbox" class="footnote-toggle" id="footnote-toggle-fn:3"><a class="footnote-ref note-ref" role="doc-noteref"><sup id="fnref:3"><label class="footnote-label" for="footnote-toggle-fn:3">3</label></sup></a><div class="side">
<p><span class="bg-number">3</span> <a href="https://twitter.com/djmicrobeads">dj microbeads</a> proposed implementing this as a standalone
project, with QR codes on the receipts &amp; a phone app that you
point at a QR code to play the sound, and that immediately didn't
feel right to me.</p>
<p>it feels like it doesn't preserve enough of the
lightness, the fact that you could put this receipt down anywhere on
your desk and it'd play, like an object that has its own magic. (maybe the receipt would have a dot frame around it, like any other page in Dynamicland, although I don't like to think about that too hard;
it would be better if it felt even lighter than that)</p>
<p>I think you at least need to have an always-on well on your desk where you can put a receipt to play it (like a slot
<a href="https://yugioh.fandom.com/wiki/Playmat">where you'd place a Yu-Gi-Oh
card</a>, but alive -- maybe
it'd have a webcam / document camera / cheap phone
mounted overhead), even if you don't have Dynamicland-esque coverage of the whole desktop; the app on your existing phone that you have to switch into is not enough&nbsp;</p>
</div> to play it</li>
</ol>
<p>like I feel like there is no audio equivalent of jotting something down
on a post-it note (or even writing on a whiteboard), and that's kinda
what I wanted: a cheap physical object, made of sound instead of
writing, where both consuming it and creating it feel immediately <a href="https://twitter.com/Malcolm_Ocean/status/1328578789933264899">at
hand</a>.</p>
<p>It'd be a mix of the nice things about audio (oral communication style
instead of written, can bring in other noise-making objects, background
sounds can make it in without your explicitly intending to include them,
music, kids/nonliterate people can participate, etc) and the nice things
about writing a note (cheap to make, disposable, objectness, can point
to and reuse later).</p>
<p>(ideas: <a href="https://twitter.com/rsnous/status/1391820268058800129">you
narrate</a> a
project you're working on, then literally stick your narration onto the
project / <a href="https://twitter.com/rsnous/status/1317195689382662144">you
hum</a> a bunch of
little sound samples and play with them to make some musical composition
/ you build a game where the game pieces are spoken words... / i don't
know. you can make non-visual systems, where you only use your hands and
ears and mouth, that would be accessible even to someone who can't read
or can't see)</p>
<hr>
<p>but -- and I think this is important -- the thing would <em>not</em> try to
recognize your speech and turn it into text. the receipt represents only
the sound itself. (from the computer's point of view, it's just an
opaque blob of audio.)<input type="checkbox" class="footnote-toggle" id="footnote-toggle-fn:4"><a class="footnote-ref note-ref" role="doc-noteref"><sup id="fnref:4"><label class="footnote-label" for="footnote-toggle-fn:4">4</label></sup></a><div class="side">
<p><span class="bg-number">4</span> maybe the receipt would have the audio waveform printed on it or
something, just to give it a unique appearance. Plus, there's this
Dynamicland aspiration that I'd want to maintain -- that a computer
could in theory look at the receipt and regenerate the audio
completely from what it sees (even if in practice it usually
'cheats' by keeping the audio file on disk)</p>
<p>(The Dynamicland aspiration is that you should be able to look at
the situation in the real world &amp; completely derive the computer
state from that; there shouldn't be invisible 'virtual state'
that lives in RAM or on a hard disk.)</p>
<p>(Ideally, if the power cut out and the computers in the ceiling at
Dynamicland all restarted, nothing would be lost, because the
physical arrangement of stuff in the real world completely
determines the behavior of the computer anyway, and that physical
arrangement remains intact.)&nbsp;</p>
</div></p>
<p>The computer is what stores the audio data for the receipt, and when you
put down the receipt, the computer is what plays the audio through the
speakers in the ceiling. So the computer's role here is to store
(audio) information and to
<a href="https://twitter.com/rsnous/status/1071586473953026050">orchestrate</a>
hardware, but its role is <em>not</em> really to digest and index that
information.</p>
<p>if you have the computer recognize the speech inside these audio
receipts and turn it into text, you're now privileging that one kind of
audio (speech), which feels weird to me. you're going to push people to
make sound in the ways that are legible to the computer. you may start
to think that the text is the 'canonical' format, and the audio is
only a temporary stop on the way to figuring out the text, and it's a
Problem if that text comes out wrong, and you'll treat everything in
the world only in terms of how you can convert it to text...</p>
<p>(and to what end? none of the ideas or aspirations I've described so
far require the computer to understand what's in the audio receipts.)</p>
<p>(sure, maybe it'd be nice to have, like, search, but should that
nice-to-have dominate the design? You can't search physical books or
post-it notes, and that's fine. I want to play with this fresh thing of
audio notes, which doesn't even exist yet, before trying to add an
extra layer of recognition and textuality and legibility, a layer which
may overwhelm some of the things about audio that were interesting to me
in the first place.)</p>
<hr>
<p>I have this reMarkable 2 tablet I got last year. I really like it. I use
it a lot. Its UI looks like this
(<a href="https://support.remarkable.com/hc/en-us/articles/360002671958-Navigating-on-your-reMarkable">source</a>):</p>
<div class="figure">
<a href="https://support.remarkable.com/hc/en-us/articles/360002671958-Navigating-on-your-reMarkable">
<img src="./assets/recognition/remarkable-ui.png" alt="screenshot of reMarkable tablet UI;
it&#39;s a Finder-like display with icons for documents and for folders">
</a>
</div>
<p>and that frustrates me a little. I feel like you could do so much more;
I feel like that interface doesn't really take the tablet and pen
<a href="https://twitter.com/rsnous/status/1215392271748780038">seriously</a>.<input type="checkbox" class="footnote-toggle" id="footnote-toggle-fn:5"><a class="footnote-ref note-ref" role="doc-noteref"><sup id="fnref:5"><label class="footnote-label" for="footnote-toggle-fn:5">5</label></sup></a><div class="side">
<p><span class="bg-number">5</span> it's such a waste! I have a pet theory that a lot of the
stagnation in programming and in GUIs in general is
<a href="https://twitter.com/rsnous/status/1321919155461713920">downstream</a>
of a stagnation in consumer <a href="https://twitter.com/rsnous/status/1085036138274775040">I/O
devices</a>.</p>
<p><a href="https://twitter.com/rsnous/status/971959408841277440">hard</a> to do,
say, graphical programming that feels good, if you're stuck with a
<a href="https://twitter.com/rsnous/status/1215659431154683904">mouse</a> and
<a href="https://twitter.com/rsnous/status/1052713036761378816">keyboard</a>.
and tablets aren't stuck with that; they have a chance to do
something new, and it feels like they've squandered it so far&nbsp;</p>
</div></p>
<p>There's so much typed text on that screen -- there are so many straight
lines and
<a href="https://twitter.com/rsnous/status/964412723680362496">buttons</a> -- it
feels like it's a UI built around
<a href="https://twitter.com/rsnous/status/1403389191371825152">tapping</a> and
clicking and maybe keyboard shortcuts, not around the pen. Shouldn't as
much of the interface as possible be handwritten text, and <a href="https://twitter.com/rsnous/status/1366910446519816192">hand-drawn
lines, and weird-shaped
regions</a>?<input type="checkbox" class="footnote-toggle" id="footnote-toggle-fn:6"><a class="footnote-ref note-ref" role="doc-noteref"><sup id="fnref:6"><label class="footnote-label" for="footnote-toggle-fn:6">6</label></sup></a><div class="side">
<p><span class="bg-number">6</span> I almost feel like I should get to draw the interface that I want
for myself. like how Acme lets you grow your own palette of commands
as you work. that would also make me feel a lot more comfortable and
committed to the interface, if it was something that came from my
own hand&nbsp;</p>
</div></p>
<p>A small example: titles. This file is called "Chapter 4":</p>
<div class="figure">
<a href="./assets/recognition/remarkable-ui-title.png"><img alt="excerpt from earlier
reMarkable UI screenshot that just shows the bottom of one document icon, with the
title &#39;Chapter 4&#39;" src="./assets/recognition/remarkable-ui-title.png"></a>
</div>
<p>if you have a tablet, with a pen, I feel like you should be able to
just... write/draw that "Chapter 4" in. you shouldn't have to <a href="https://twitter.com/atomicthumbs/status/1255766053264560130">Make
a New
File</a>,
then type C-H-A-P-T-E-R-SPACE-4 in a text field, then click
OK... there shouldn't even really be a 'text field' at all on a
tablet like that; at minimum, it should be an open blank field where
you can draw or write anything with your pen.</p>
<p>even if the computer can't figure out what some little scribble in that
field means, it is still useful, since the title is there to serve <em>me</em>,
to help me spot my files on sight. and in fact, even if the tablet does
manage to recognize the text in my scrawled title, I'd prefer that it
show my original handwriting there, because then the title feels like
it's <em>mine</em>, it's my writing from my hand, with my weird quirks and
imperfections. it's not dead 'text' from some font built into the OS</p>
<p>why is there <em>any</em> typed text on the tablet UI? why am I typing a title
by mashing soft keys on a software keyboard? shouldn't it all be
handwritten? not only would it be more comfortable and more fun (the
tablet hardware is great for handwriting and terrible for typing), it
would be more <em>open</em>: I could draw little smiley faces or stars or
whatever I want. (I could 'star' a document by literally drawing a
star on it!)<input type="checkbox" class="footnote-toggle" id="footnote-toggle-fn:7"><a class="footnote-ref note-ref" role="doc-noteref"><sup id="fnref:7"><label class="footnote-label" for="footnote-toggle-fn:7">7</label></sup></a><div class="side">
<p><span class="bg-number">7</span> and why are there files and folders at all? it feels like a naive,
traditional-PC-derivative take on how to deal with information. why
can't I just have endless pages, where I mark out and wire regions
of them together with my magic pen?&nbsp;</p>
</div></p>
<p>anyway, if we want legibility, we could imagine techniques to navigate
and visualize that space of titles/title-drawings that aren't just
about converting everything to text and treating it as text:</p>
<div class="figure">
<a href="https://twitter.com/rsnous/status/1356647749182058496">
<img alt="screenshot of linked tweet" src="./assets/recognition/corners.png">
</a>
</div>
<p>it's weird that tablets like the reMarkable or iPad don't use this
more in their interfaces. like Dynamicland, they have a new form of
input, a form that goes way beyond traditional mouse and keyboard or
touch, that is far more open-ended, and I think they should use it!
pervasively!</p>
<hr>
<p>and I don't mean treating handwriting as just <a href="https://support.apple.com/en-us/HT211774">an input to a
recognition system</a> that slots
into old interface paradigm:</p>
<div class="figure">
<img alt="screenshot of &#39;Write in any text field with Scribble&#39; section of Apple page,
showing &#39;Carmel&#39; scrawled into Apple Maps search box" src="./assets/recognition/ipad-scribble.png">
</div>
<p>(I understand why that form of text recognition is useful -- existing
systems are big, and they do a lot of stuff you can't replicate easily,
and some form of pen compatibility with them is important -- but it
doesn't excite me, and I feel like it limits our imagination if we
think too much about it)</p>
<hr>
<p>A couple of years ago, we wanted to have a better idea of what projects
people were doing (and had done already) at Dynamicland, so we started
making this 'research gallery' application.<input type="checkbox" class="footnote-toggle" id="footnote-toggle-fn:8"><a class="footnote-ref note-ref" role="doc-noteref"><sup id="fnref:8"><label class="footnote-label" for="footnote-toggle-fn:8">8</label></sup></a><div class="side">
<p><span class="bg-number">8</span> and we wanted to think about how you would make a 'database' or
querying interface that takes advantage of the unique properties of
Dynamicland, and we wanted more applications in DL that actually got
regularly used in a real context.&nbsp;</p>
</div></p>
<p>It was built around this dynamic 'scrapbook'. The idea was that when
you make something, you'd add a new page to the scrapbook about it,
with photos, videos, text description, maybe a little embedded demo of
the thing, and so on.<input type="checkbox" class="footnote-toggle" id="footnote-toggle-fn:9"><a class="footnote-ref note-ref" role="doc-noteref"><sup id="fnref:9"><label class="footnote-label" for="footnote-toggle-fn:9">9</label></sup></a><div class="side">
<p><span class="bg-number">9</span> reminds me a bit of <a href="https://twitter.com/bschne/status/1393821742523731969">the Lisa Polaroids</a> :-)&nbsp;</p>
</div></p>
<div class="figure">
<img alt="photo of &#39;BART departures&#39; page of scrapbook" src="./assets/recognition/departures.jpg">
</div>
<p>You can see two such scrapbook pages below -- on the left, a page about
the "Animation" project, and on the right, a page about the "DNA
Kit" project:</p>
<div class="figure">
<img alt="photo of two pages of scrapbook" src="./assets/recognition/scrapbook.jpg">
</div>
<p>Each project at Dynamicland would get a big page (or two or three) in
the scrapbook.</p>
<p>You can see (your eyes were probably drawn to) all the iconic
Dynamicland dot-framed pages that are glued into the scrapbook. These
pages are a few different things:</p>
<ul>
<li>photos that have been printed out via the Dynamicland system (for
example, the yellow-backed areas in Animation): the photo is
actually printed on the paper, but the computer also knows where
and what the photo is and can transclude it onto the wall or as a
thumbnail in search results or whatever</li>
<li>demo videos that play on the scrapbook (the purple "History" in
Animation)</li>
<li>an embedded, live instance of the project itself (bottom-left
corner of Animation, which animates between the 3 hand drawings
along the bottom center of the page)</li>
</ul>
<p>But I don't actually want to talk about those dot-frames, or about
their behavior; they're not the part that I find interesting. I'm much
more interested in how you can really put <em>anything you want</em> on the
scrapbook page (it is, after all, just a big piece of paper).</p>
<p>Look at everything on the Animation scrapbook page that <em>isn't</em> framed
by colored dots:</p>
<div class="figure">
<img alt="left side of prev photo of scrapbook, showing just Animation
page, and now with dotframed areas grayed out" src="./assets/recognition/scrapbook-unrecognized.jpg">
</div>
<p>These are things -- post-it notes, bits of text floating around that
were written by different people, handwritten headings -- where the
computer doesn't even know they're there. But they mean something to
you and me. And, unlike 'text' in a computer, they can vary in human
ways; they can be written or <a href="https://twitter.com/rsnous/status/1262961680121618432">typeset
differently</a>, set
at different sizes, with different colors, and so on, without software
needing to implement any of those features.</p>
<p>It's like how I can yell or cry or laugh in an audio recording, but all
that meaning gets destroyed when it gets 'recognized' into text.</p>
<hr>
<p>When we made the scrapbook, we struggled a lot with the tension between
the freedom of this unrecognized 'open input space' and the utility of
a scrapbook that is indexable/legible to the computer. The scrapbook you
see above was a sort of compromise, with both structured (dot-framed)
and unstructured (everything else) elements. I wrote a bit about this
tension at the time, in an unpublished draft:</p>
<blockquote>
<p>Let's say we only had a physical scrapbook of projects, with no
structured data -- no computer at all, basically. There's something
freeing about that <em>open space</em> format: you can put whatever you want
into the book. Photos, handwritten notes, hand-drawn diagrams,
booklets stapled in, paper inserts that fold out, whatever.</p>
<p>But in exchange for that freedom, you get a book which is in some ways
profoundly illegible and unsearchable. How would you search for
projects that involve 'music'? How would you search for projects
'made by Omar'?</p>
<p>Unless the book had an index or table of contents for that specific
kind of query (and you kept that index updated by hand, every time you
added or changed a project), you'd have to scan through the book from
cover to cover to answer the query.</p>
<p>So when we made the research gallery, we wanted its users to have the
power of a computer to process <em>structured data</em>:</p>
<ul>
<li>
<p>search for projects,</p>
</li>
<li>
<p>see many views of projects (by date, by author, by subject, by
capabilities used...),</p>
</li>
<li>
<p>filter only for what you're interested in,</p>
</li>
<li>
<p>see connections to related work,</p>
</li>
<li>
<p>quickly render a list of results.</p>
</li>
</ul>
<p>We want the computer to understand some things about each project. But
once we make a project format that is easy for the computer to read,
we also circumscribe how authors can describe a project. The system
wants authors to say the kinds of structured things that it can
understand, like:</p>
<ul>
<li>
<p><strong>a project is described by strings of (QWERTY-keyboard-typeable)
text</strong>, not diagrams, or icons, or singing, or other languages, or
handwriting where the author used a different pen and pressed
harder on some parts to emphasize them</p>
</li>
<li>
<p><strong>a project was created on a particular date on the calendar</strong>,
not 'some time from Omar here and some time from Paula there,
with low-level thinking and tweaking all along as part of a
different project X, and then a big overhaul 6 months later'</p>
</li>
<li>
<p><strong>a project is demonstrated in action by individual photos and
videos</strong>, not a big collage of photos with stuff pasted in like
handwritten captions and supplementary drawings and extra people
who weren't captured in the original photos</p>
</li>
</ul>
</blockquote>
<p>To be honest -- I would have liked to not have any dot frames on the
scrapbook page at all -- I would have liked for that 'open input
space' to be the primary thing, and the recognition system to come
later (if at all).<input type="checkbox" class="footnote-toggle" id="footnote-toggle-fn:10"><a class="footnote-ref note-ref" role="doc-noteref"><sup id="fnref:10"><label class="footnote-label" for="footnote-toggle-fn:10">10</label></sup></a><div class="side">
<p><span class="bg-number">10</span> and the dots take so much space! to me, the fact that they
dominate your visual field feels so wrong, so misleading about
what's really important. and it constrains the number of
'objects' that can fit on the page so much when each 'object'
has this thick dot-frame around it. it constrains your imagination
of what the scrapbook can be. i wish objects could be small and free
and unrecognized&nbsp;</p>
</div> (and if that means the computer has to give up
some legibility for a while, if that means you can't automatically
figure out a thumbnail photo for a scrapbook page, if that means you
can't search through the scrapbook quickly, that might have been OK by
me.)</p>
<hr>
<p>the idea that a lot of
<a href="https://twitter.com/rsnous/status/1399491039099035657">things</a> in the
computer are <a href="https://twitter.com/rsnous/status/1259114530908454915">not really about
computation</a>;
they are artifacts made by people for people. it should be normal to put
<a href="https://twitter.com/rsnous/status/1361081403912249345">things</a>
<a href="https://twitter.com/rsnous/status/1402665296704442373">inside</a> the
computer that the computer itself cannot digest, but that it can <a href="https://twitter.com/rsnous/status/1387841669479862274">pass
on</a> to your
future self or to other people.</p>
<p>this is sort of the idea behind literate programming, too -- the idea
that <a href="https://twitter.com/rsnous/status/1402635482840932358">the stuff for humans should be the default
context</a>, and the
highly constrained stuff parsed by the computer should be an exceptional
mode within that.</p>
<hr>
<p>It's not that I think that recognition is always bad -- but I do think
it is more interesting to err against it when we're designing new
systems.</p>
<p>(and I think framing your problems in terms of 'recognition' is
actually risky; it may result in really ossified, unimaginative systems.
You end up with some expert who works on the 'recognition module' of
your system, and their job is to take some fixed form of input and
deliver some fixed form of output, and they can improve that module as
much as they want, but they don't think about the interface context
around the recognition. Even if you want recognition, I think there
should be someone who <em>thinks about the whole system at once</em> and can
come up with an
<a href="https://twitter.com/rsnous/status/1296366843439980544">end-to-end</a>
<a href="https://twitter.com/rsnous/status/1348343829934481408">design</a> that
includes both pattern recognition and user interface.)</p>
<p>We have all these computer systems that love lowest-common-denominator
formats like plain text, and they push programmers to normalize
everything into those formats, so the computer can 'understand' them.</p>
<div class="figure">
<a href="https://twitter.com/dannybirchall/status/1068475229087940608">
<img alt="screenshot of linked tweet" src="./assets/recognition/data-as-ashes.png">
</a>
</div>
<p>But I feel like as much as possible, the computer should be leaving
things the way they are!</p>
<div class="figure">
<a href="https://twitter.com/rsnous/status/1352720374182502400?ref_src=twsrc%5Etfw">
<img alt="screenshot of linked tweet" src="./assets/recognition/morphs.png">
</a>
</div>
<p>If you have recognition, it should be a sort of overlay you put on the
thing (maybe one of many such overlays); you shouldn't destroy the
thing and replace it with its ashes.</p>
<p>If it has to exist, the text recognizer should attach an overlay to the
image that says 'it might have this text in it'; the image shouldn't
itself be <em>transformed into</em> text. (and ideally, that overlay would be
rich with context and provenance; it wouldn't just be a blob of plain
text; it would know what image it's from, admit other texts that it
could potentially be, talk about how likely each word of it is to be
correct, say as much as possible about the recognizer's process and
thinking)</p>
<p>The original thing is still around and is still the source of truth.</p>
<div class="figure">
<a href="https://twitter.com/rsnous/status/1358130329098178560">
<img alt="screenshot of linked tweet" src="./assets/recognition/original-screenshot.png">
</a>
</div>
<hr>
<p>mostly, this email is not an argument; i don't know if it really makes
any sense; it's a feeling</p>
<p>i feel like the computer should give you more space to play. like you
should be able to play and doodle and dream by default, wherever you
happen to be on the computer, without your first concern being whether
the computer will recognize it...</p>
<div class="figure">
<a href="https://twitter.com/rsnous/status/1403053716924731397">
<img alt="screenshot of linked tweet" src="./assets/recognition/excel-home.png">
</a>
</div>
<p>my computer's first job is not to recognize things; it's to hold onto
what I put in it. it's a medium, not an intelligence; i want it to be
good at being a sheet of paper before it tries to be anything else.
(it's a
<a href="https://twitter.com/rsnous/status/1290770649716121600">versatile</a> sheet
of paper: it can hold video, and sound, and links, and computations, and
...)</p>


    </div>
  </article>
</main>
   </article>
   <footer>
   </footer>



</body></html>